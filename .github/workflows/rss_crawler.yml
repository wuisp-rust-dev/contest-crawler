name: Scrape Notices

on:
  schedule:
    - cron: "0 * * * *"      # 매 시간 실행
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages-deploy
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Set up Rust (stable)
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: Swatinem/rust-cache@v2

      - name: Install system dependencies
        run: sudo apt-get update && sudo apt-get install -y pkg-config libssl-dev

      - name: Build (optional, run will build anyway)
        run: cargo build --release

      - name: Run scraper (write RSS files under public/contest-rss)
        env:
          RSS_DIR: public/contest-rss
          RSS_WEVITY: public/contest-rss/wevity_rss.xml
          RSS_CAMPUS: public/contest-rss/campus_pick_rss.xml
          RSS_DACON:  public/contest-rss/dacon_rss.xml
          RSS_MERGED: public/contest-rss/merged_rss.xml
        run: |
          mkdir -p public/contest-rss
          cargo run --release
          # (선택) 루트에서도 접근 가능하게 하려면:
          # cp public/contest-rss/merged_rss.xml public/rss.xml

      - name: Debug list
        run: ls -R public

      - name: Upload artifact (deploy root = public)
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:                              # ← 반드시 이 들여쓰기가 필요합니다
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

